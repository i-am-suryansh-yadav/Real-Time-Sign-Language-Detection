# âœ‹ Real-Time Indian Sign Language (ISL) Aâ€“Z Detection  
### Developed by **Suryansh Yadav**

A real-time computer vision system that detects **Indian Sign Language alphabet gestures (Aâ€“Z)** using MediaPipe, OpenCV, and a machine-learning model trained on 63-dimensional hand landmark features.

---

## ğŸš€ Features

### ğŸ¥ Real-Time Hand Tracking
- Uses **MediaPipe Hands** to extract 21 landmark points (63 values)
- Displays landmarks on webcam feed in real-time

### ğŸ”¤ ISL Alphabet Recognition
- Trained ML model (RandomForest) achieves **98â€“100% accuracy**
- Predicts letter + Hindi equivalent:
  - A â†’ à¤•
  - B â†’ à¤–
  - C â†’ à¤—
  - ...

### ğŸ¯ Confidence Percentage
- Displays model confidence (e.g., `99.2%`) next to predictions

### ğŸ§© Word Builder
- Forms words from sequential predictions  
  `H E L L O â†’ HELLO`

### ğŸ’¾ Demo Recording
- Press **R** to record live demo: `demo_week1.mp4`

### ğŸŒ Web App (Flask)
- Stream webcam feed + predictions directly in browser
- Works on Chrome, Edge, Firefox

---

## ğŸ“Š Dataset Source

This project uses publicly available datasets from Kaggle:

- ğŸ”— [Indian Sign Language Dataset by Soumya Kushwaha](https://www.kaggle.com/datasets/soumyakushwaha/indian-sign-language-dataset)
- ğŸ”— [Indian Sign Language ISL Dataset by Prathuma Rikeri](https://www.kaggle.com/datasets/prathumarikeri/indian-sign-language-isl)

These contain labeled hand gesture images for Aâ€“Z, which are converted to hand landmarks and used for model training.

---

## ğŸ“ Project Structure

Real-Time-Sign-Language-Detection/
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ isl_landmarks.csv # Final merged dataset (ignored in Git)
â”‚
â”œâ”€â”€ models/
â”‚ â””â”€â”€ isl_model.pkl # Trained ML model (ignored in Git)
â”‚
â”œâ”€â”€ screenshots/ # Saved screenshots (optional)
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ convert_photo_to_landmarks.py # Image to landmark converter
â”‚ â”œâ”€â”€ merge.py # Merge CSVs into one dataset
â”‚ â”œâ”€â”€ train_model.py # Train the RandomForest model
â”‚ â”œâ”€â”€ detect_live.py # Live webcam letter detection
â”‚ â””â”€â”€ web_app.py # Flask app for web UI
â”‚
â”œâ”€â”€ ui/
â”‚ â”œâ”€â”€ index.html # Landing page
â”‚ â”œâ”€â”€ style.css # Neon-themed styling
â”‚ â””â”€â”€ static/ # Static resources like CSS
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md

## ğŸ›  Requirements

Install all dependencies inside the virtual environment:

pip install opencv-python mediapipe scikit-learn numpy pandas joblib flask

âš™ï¸ Setup Guide
1ï¸âƒ£ Clone the Repository
git clone https://github.com/<your-username>/Real-Time-Sign-Language-Detection.git
cd Real-Time-Sign-Language-Detection
2ï¸âƒ£ Create and Activate Virtual Environment
python -m venv env
env\Scripts\activate
3ï¸âƒ£ Install Libraries
pip install -r requirements.txt
# or install manually as shown above
4ï¸âƒ£ Add Dataset
Place your final CSV here:
data/isl_landmarks.csv
5ï¸âƒ£ Train the Model
python src/train_model.py
â–¶ï¸ Run the Real-Time Detector
python src/detect_live.py

ğŸ› Keyboard Controls:
Key	Action
r	Start/stop recording
s	Save screenshot
c	Clear formed word
q	Quit

ğŸŒ Web Application (Browser View)
python src/web_app.py
Then open:
http://localhost:5000

You will see:
Live webcam
Detected landmarks
Prediction (Aâ€“Z)
Hindi letter
Confidence score

ğŸ“¸ Screenshots
Screenshots are saved in the screenshots/ folder. Recommended shots:

Each letter Aâ€“Z

Word builder in action

Hindi letter display

Flask web app interface

ğŸ§  Technologies Used
Technology	Purpose
MediaPipe Hands	Real-time hand landmark extraction
OpenCV	Webcam video + annotation overlay
scikit-learn	ML classification (RandomForest)
NumPy	Vector preprocessing
Joblib	Save/load ML models
Flask	Live browser-based UI
HTML/CSS	Neon-style user interface

ğŸ¯ Accuracy Achieved
Dataset: 26 letters Ã— 50 samples Ã— 5 datasets = 6,500+ samples

Accuracy: 98â€“100% on clean data

Inference speed: Real-time (30 FPS on average webcam)

ğŸ‘¨â€ğŸ’» Developer
Developed by:
Suryansh Yadav
December 2025